# -*- coding: utf-8 -*-
"""GCN model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RAsVtS7sE_QkTk-s6-U_LusdSOIhIqMU
"""

import pickle as pkl
import numpy as np

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Input, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

from spektral.data.loaders import SingleLoader
from spektral.datasets.citation import Citation
from spektral.layers import GCNConv
from spektral.transforms import LayerPreprocess, AdjToSpTensor
from spektral.data import Graph

from tensorflow import keras

# Masks are boolean arrays that have the same size as the dataset which are used
# specify the data points to be used for train, testing or validation.

# Specify the percentage of data to be used for training and validation. The rest
# will be used for testing.
def get_masks(mask_size, train_portion, valid_portion):
    all_indices = [i for i in range(mask_size)]
    left = mask_size
    train_size = int(train_portion * mask_size)
    train_indices = list(np.random.choice(all_indices, train_size, replace=False))
    left -= train_size

    # print(train_indices)
    # print(all_indices)

    for i in train_indices:
        all_indices.remove(i)
    
    valid_size = int(valid_portion * mask_size)
    valid_indices = list(np.random.choice(all_indices, valid_size, replace=False))

    #print(len(valid_indices), len(train_indices))

    for i in valid_indices:
        if i in train_indices:
            print(True)
    
    for i in valid_indices:
        all_indices.remove(i)
    
    left -= valid_size

    test_indices = list(np.random.choice(all_indices, left, replace=False))

    for i in test_indices:
        if i in train_indices:
            print(True)

        if i in valid_indices:
            print(True)
    
    train_mask = [True if i in train_indices else False for i in range(mask_size)]
    valid_mask = [True if i in valid_indices else False for i in range(mask_size)]
    test_mask = [True if i in test_indices else False for i in range(mask_size)]

    return train_mask, valid_mask, test_mask

x = None # Feature matrix: shape - (num_nodes, num_features)
a = None # Adjacency matrix: shape - (num_nodes, num_nodes)
y = None # Labels: shape - (num_nodes, num_labels)

with open('fea', 'rb') as fp:
  x = pkl.load(fp)

with open('adj', 'rb') as fp:
  a = pkl.load(fp)

with open('labels', 'rb') as fp:
  y = pkl.load(fp)

dataset = [Graph(x=x, a=a, y=y)]

train_mask, valid_mask, test_mask = get_masks(581, 0.8, 0.1)
mask_tr = np.array(train_mask)
mask_va = np.array(valid_mask)
mask_te = np.array(test_mask)

dropout = 0.5          # Dropout rate for the features
l2_reg = 5e-4 / 2      # L2 regularization rate
learning_rate = 1e-2   # Learning rate
epochs = 200           # Number of training epochs
a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1

N = 581       # Number of nodes in the graph
F = 10        # Original size of node features
n_out = 2     # Number of classes

# Specify the layers. This model has a single GCN.

x_in = Input(shape=(F,))
a_in = Input((N,), sparse=True, dtype=a_dtype)

do_1 = Dropout(dropout)(x_in)
gc_1 = GCNConv(n_out,
               activation='softmax',
               kernel_regularizer=l2(l2_reg),
               use_bias=False)([do_1, a_in])

model = Model(inputs=[x_in, a_in], outputs=gc_1)
optimizer = Adam(lr=learning_rate)
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              weighted_metrics=['acc'])
model.summary()

# Fit the model

loader_tr = SingleLoader(dataset, sample_weights=mask_tr)
loader_va = SingleLoader(dataset, sample_weights=mask_va)
history = model.fit(loader_tr.load(),
          steps_per_epoch=loader_tr.steps_per_epoch,
          validation_data=loader_va.load(),
          validation_steps=loader_va.steps_per_epoch,
          epochs=epochs)

print('Evaluating model.')
loader_te = SingleLoader(dataset, sample_weights=mask_te)
eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)
print('Done.\n'
      'Test loss: {}\n'
      'Test accuracy: {}'.format(*eval_results))

"""# New Section"""

# print('Prediction')
# preds = model.predict(np.zeros((1, 10)))
# labels = [np.argmax(x) for x in preds]

# loaded_model = keras.models.load_model("model0208/")
x = np.array([22, 1, 45, 11, 0, 1, 1, 0, 1, 0]).reshape(1,10)
a = np.array([1]).reshape(1,1)
y = np.array([0, 1]).reshape(1,2)

dataset = [Graph(x=x, a=a, y=y)]
loader_te = SingleLoader(dataset, sample_weights=np.array([1]))
print(model.predict(loader_te.load(), steps=loader_te.steps_per_epoch))


